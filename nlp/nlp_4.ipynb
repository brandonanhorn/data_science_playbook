{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP #4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some visual examples for NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# importing Counter to get word counts for bag of words\n",
    "from collections import Counter\n",
    "# importing part-of-speech function for lemmatization\n",
    "from part_of_speech import get_part_of_speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "    She packed my bags last night pre-flight\n",
    "Zero hour nine A.M.\n",
    "And I'm gonna be high as a kite by then\n",
    "I miss the earth so much, I miss my wife\n",
    "It's lonely out in space\n",
    "On such a timeless flight\n",
    "And I think it's gonna be a long long time\n",
    "'Til touchdown brings me 'round again to find\n",
    "I'm not the man they think I am at home\n",
    "Oh, no, no, no.\n",
    "I'm a rocket man\n",
    "Rocket man burning out his fuse up here alone\n",
    "And I think it's gonna be a long long time\n",
    "'Til touchdown brings me 'round again to find\n",
    "I'm not the man they think I am at home\n",
    "Oh, no, no, no.\n",
    "I'm a rocket man\n",
    "Rocket man burning out his fuse up here alone\n",
    "Mars ain't the kind of place to raise your kids\n",
    "In fact it's cold as hell\n",
    "And there's no one there to raise them if you did\n",
    "And all this science I don't understand\n",
    "It's just my job five days a week\n",
    "A rocket man, a rocket man\n",
    "And I think it's gonna be a long long time\n",
    "'Til touchdown brings me 'round again to find\n",
    "I'm not the man they think I am at home\n",
    "Oh, no, no, no.\n",
    "I'm a rocket man\n",
    "Rocket man burning out his fuse up here alone\n",
    "And I think it's gonna be a long long time\n",
    "'Til touchdown brings me 'round again to find\n",
    "I'm not the man they think I am at home\n",
    "Oh, no, no, no.\n",
    "I'm a rocket man\n",
    "Rocket man burning out his fuse up here alone\n",
    "And I think it's gonna be a long long time\n",
    "And I think it's gonna be a long long time\n",
    "And I think it's gonna be a long long time\n",
    "And I think it's gonna be a long long time\n",
    "And I think it's gonna be a long long time\n",
    "And I think it's gonna be a long long time\n",
    "And I think it's gonna be a long long time\n",
    "And I think it's gonna be a long long time\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " She packed my bags last night pre flight Zero hour nine A M And I m gonna be high as a kite by then I miss the earth so much I miss my wife It s lonely out in space On such a timeless flight And I think it s gonna be a long long time Til touchdown brings me round again to find I m not the man they think I am at home Oh no no no I m a rocket man Rocket man burning out his fuse up here alone And I think it s gonna be a long long time Til touchdown brings me round again to find I m not the man they think I am at home Oh no no no I m a rocket man Rocket man burning out his fuse up here alone Mars ain t the kind of place to raise your kids In fact it s cold as hell And there s no one there to raise them if you did And all this science I don t understand It s just my job five days a week A rocket man a rocket man And I think it s gonna be a long long time Til touchdown brings me round again to find I m not the man they think I am at home Oh no no no I m a rocket man Rocket man burning out his fuse up here alone And I think it s gonna be a long long time Til touchdown brings me round again to find I m not the man they think I am at home Oh no no no I m a rocket man Rocket man burning out his fuse up here alone And I think it s gonna be a long long time And I think it s gonna be a long long time And I think it s gonna be a long long time And I think it s gonna be a long long time And I think it s gonna be a long long time And I think it s gonna be a long long time And I think it s gonna be a long long time And I think it s gonna be a long long time \n",
      "['She', 'packed', 'my', 'bags', 'last', 'night', 'pre', 'flight', 'Zero', 'hour', 'nine', 'A', 'M', 'And', 'I', 'm', 'gon', 'na', 'be', 'high', 'as', 'a', 'kite', 'by', 'then', 'I', 'miss', 'the', 'earth', 'so', 'much', 'I', 'miss', 'my', 'wife', 'It', 's', 'lonely', 'out', 'in', 'space', 'On', 'such', 'a', 'timeless', 'flight', 'And', 'I', 'think', 'it', 's', 'gon', 'na', 'be', 'a', 'long', 'long', 'time', 'Til', 'touchdown', 'brings', 'me', 'round', 'again', 'to', 'find', 'I', 'm', 'not', 'the', 'man', 'they', 'think', 'I', 'am', 'at', 'home', 'Oh', 'no', 'no', 'no', 'I', 'm', 'a', 'rocket', 'man', 'Rocket', 'man', 'burning', 'out', 'his', 'fuse', 'up', 'here', 'alone', 'And', 'I', 'think', 'it', 's', 'gon', 'na', 'be', 'a', 'long', 'long', 'time', 'Til', 'touchdown', 'brings', 'me', 'round', 'again', 'to', 'find', 'I', 'm', 'not', 'the', 'man', 'they', 'think', 'I', 'am', 'at', 'home', 'Oh', 'no', 'no', 'no', 'I', 'm', 'a', 'rocket', 'man', 'Rocket', 'man', 'burning', 'out', 'his', 'fuse', 'up', 'here', 'alone', 'Mars', 'ain', 't', 'the', 'kind', 'of', 'place', 'to', 'raise', 'your', 'kids', 'In', 'fact', 'it', 's', 'cold', 'as', 'hell', 'And', 'there', 's', 'no', 'one', 'there', 'to', 'raise', 'them', 'if', 'you', 'did', 'And', 'all', 'this', 'science', 'I', 'don', 't', 'understand', 'It', 's', 'just', 'my', 'job', 'five', 'days', 'a', 'week', 'A', 'rocket', 'man', 'a', 'rocket', 'man', 'And', 'I', 'think', 'it', 's', 'gon', 'na', 'be', 'a', 'long', 'long', 'time', 'Til', 'touchdown', 'brings', 'me', 'round', 'again', 'to', 'find', 'I', 'm', 'not', 'the', 'man', 'they', 'think', 'I', 'am', 'at', 'home', 'Oh', 'no', 'no', 'no', 'I', 'm', 'a', 'rocket', 'man', 'Rocket', 'man', 'burning', 'out', 'his', 'fuse', 'up', 'here', 'alone', 'And', 'I', 'think', 'it', 's', 'gon', 'na', 'be', 'a', 'long', 'long', 'time', 'Til', 'touchdown', 'brings', 'me', 'round', 'again', 'to', 'find', 'I', 'm', 'not', 'the', 'man', 'they', 'think', 'I', 'am', 'at', 'home', 'Oh', 'no', 'no', 'no', 'I', 'm', 'a', 'rocket', 'man', 'Rocket', 'man', 'burning', 'out', 'his', 'fuse', 'up', 'here', 'alone', 'And', 'I', 'think', 'it', 's', 'gon', 'na', 'be', 'a', 'long', 'long', 'time', 'And', 'I', 'think', 'it', 's', 'gon', 'na', 'be', 'a', 'long', 'long', 'time', 'And', 'I', 'think', 'it', 's', 'gon', 'na', 'be', 'a', 'long', 'long', 'time', 'And', 'I', 'think', 'it', 's', 'gon', 'na', 'be', 'a', 'long', 'long', 'time', 'And', 'I', 'think', 'it', 's', 'gon', 'na', 'be', 'a', 'long', 'long', 'time', 'And', 'I', 'think', 'it', 's', 'gon', 'na', 'be', 'a', 'long', 'long', 'time', 'And', 'I', 'think', 'it', 's', 'gon', 'na', 'be', 'a', 'long', 'long', 'time', 'And', 'I', 'think', 'it', 's', 'gon', 'na', 'be', 'a', 'long', 'long', 'time']\n"
     ]
    }
   ],
   "source": [
    "cleaned = re.sub('\\W+', ' ', text)\n",
    "tokenized = word_tokenize(cleaned)\n",
    "print(cleaned)\n",
    "print(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/brandonanhorn19/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
      "['She', 'packed', 'bags', 'last', 'night', 'pre', 'flight', 'Zero', 'hour', 'nine', 'A', 'M', 'And', 'I', 'gon', 'na', 'high', 'kite', 'I', 'miss', 'earth', 'much', 'I', 'miss', 'wife', 'It', 'lonely', 'space', 'On', 'timeless', 'flight', 'And', 'I', 'think', 'gon', 'na', 'long', 'long', 'time', 'Til', 'touchdown', 'brings', 'round', 'find', 'I', 'man', 'think', 'I', 'home', 'Oh', 'I', 'rocket', 'man', 'Rocket', 'man', 'burning', 'fuse', 'alone', 'And', 'I', 'think', 'gon', 'na', 'long', 'long', 'time', 'Til', 'touchdown', 'brings', 'round', 'find', 'I', 'man', 'think', 'I', 'home', 'Oh', 'I', 'rocket', 'man', 'Rocket', 'man', 'burning', 'fuse', 'alone', 'Mars', 'kind', 'place', 'raise', 'kids', 'In', 'fact', 'cold', 'hell', 'And', 'one', 'raise', 'And', 'science', 'I', 'understand', 'It', 'job', 'five', 'days', 'week', 'A', 'rocket', 'man', 'rocket', 'man', 'And', 'I', 'think', 'gon', 'na', 'long', 'long', 'time', 'Til', 'touchdown', 'brings', 'round', 'find', 'I', 'man', 'think', 'I', 'home', 'Oh', 'I', 'rocket', 'man', 'Rocket', 'man', 'burning', 'fuse', 'alone', 'And', 'I', 'think', 'gon', 'na', 'long', 'long', 'time', 'Til', 'touchdown', 'brings', 'round', 'find', 'I', 'man', 'think', 'I', 'home', 'Oh', 'I', 'rocket', 'man', 'Rocket', 'man', 'burning', 'fuse', 'alone', 'And', 'I', 'think', 'gon', 'na', 'long', 'long', 'time', 'And', 'I', 'think', 'gon', 'na', 'long', 'long', 'time', 'And', 'I', 'think', 'gon', 'na', 'long', 'long', 'time', 'And', 'I', 'think', 'gon', 'na', 'long', 'long', 'time', 'And', 'I', 'think', 'gon', 'na', 'long', 'long', 'time', 'And', 'I', 'think', 'gon', 'na', 'long', 'long', 'time', 'And', 'I', 'think', 'gon', 'na', 'long', 'long', 'time', 'And', 'I', 'think', 'gon', 'na', 'long', 'long', 'time']\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = stopwords.words('english')\n",
    "filtered = [word for word in tokenized if word not in stop_words]\n",
    "print(stop_words)\n",
    "print(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['She', 'pack', 'bag', 'last', 'night', 'pre', 'flight', 'Zero', 'hour', 'nine', 'A', 'M', 'And', 'I', 'gon', 'na', 'high', 'kite', 'I', 'miss', 'earth', 'much', 'I', 'miss', 'wife', 'It', 'lonely', 'space', 'On', 'timeless', 'flight', 'And', 'I', 'think', 'gon', 'na', 'long', 'long', 'time', 'Til', 'touchdown', 'bring', 'round', 'find', 'I', 'man', 'think', 'I', 'home', 'Oh', 'I', 'rocket', 'man', 'Rocket', 'man', 'burn', 'fuse', 'alone', 'And', 'I', 'think', 'gon', 'na', 'long', 'long', 'time', 'Til', 'touchdown', 'bring', 'round', 'find', 'I', 'man', 'think', 'I', 'home', 'Oh', 'I', 'rocket', 'man', 'Rocket', 'man', 'burn', 'fuse', 'alone', 'Mars', 'kind', 'place', 'raise', 'kid', 'In', 'fact', 'cold', 'hell', 'And', 'one', 'raise', 'And', 'science', 'I', 'understand', 'It', 'job', 'five', 'day', 'week', 'A', 'rocket', 'man', 'rocket', 'man', 'And', 'I', 'think', 'gon', 'na', 'long', 'long', 'time', 'Til', 'touchdown', 'bring', 'round', 'find', 'I', 'man', 'think', 'I', 'home', 'Oh', 'I', 'rocket', 'man', 'Rocket', 'man', 'burn', 'fuse', 'alone', 'And', 'I', 'think', 'gon', 'na', 'long', 'long', 'time', 'Til', 'touchdown', 'bring', 'round', 'find', 'I', 'man', 'think', 'I', 'home', 'Oh', 'I', 'rocket', 'man', 'Rocket', 'man', 'burn', 'fuse', 'alone', 'And', 'I', 'think', 'gon', 'na', 'long', 'long', 'time', 'And', 'I', 'think', 'gon', 'na', 'long', 'long', 'time', 'And', 'I', 'think', 'gon', 'na', 'long', 'long', 'time', 'And', 'I', 'think', 'gon', 'na', 'long', 'long', 'time', 'And', 'I', 'think', 'gon', 'na', 'long', 'long', 'time', 'And', 'I', 'think', 'gon', 'na', 'long', 'long', 'time', 'And', 'I', 'think', 'gon', 'na', 'long', 'long', 'time', 'And', 'I', 'think', 'gon', 'na', 'long', 'long', 'time']\n"
     ]
    }
   ],
   "source": [
    "normalizer = WordNetLemmatizer()\n",
    "normalized = [normalizer.lemmatize(token, get_part_of_speech(token)) for token in filtered]\n",
    "print(normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'I': 28, 'long': 24, 'think': 16, 'And': 15, 'man': 14, 'gon': 13, 'na': 13, 'time': 12, 'rocket': 6, 'Til': 4, 'touchdown': 4, 'bring': 4, 'round': 4, 'find': 4, 'home': 4, 'Oh': 4, 'Rocket': 4, 'burn': 4, 'fuse': 4, 'alone': 4, 'flight': 2, 'A': 2, 'miss': 2, 'It': 2, 'raise': 2, 'She': 1, 'pack': 1, 'bag': 1, 'last': 1, 'night': 1, 'pre': 1, 'Zero': 1, 'hour': 1, 'nine': 1, 'M': 1, 'high': 1, 'kite': 1, 'earth': 1, 'much': 1, 'wife': 1, 'lonely': 1, 'space': 1, 'On': 1, 'timeless': 1, 'Mars': 1, 'kind': 1, 'place': 1, 'kid': 1, 'In': 1, 'fact': 1, 'cold': 1, 'hell': 1, 'one': 1, 'science': 1, 'understand': 1, 'job': 1, 'five': 1, 'day': 1, 'week': 1})\n"
     ]
    }
   ],
   "source": [
    "bag_of_looking_glass_words = Counter(normalized)\n",
    "print(bag_of_looking_glass_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecg_text = 'An electrocardiogram is used to record the electrical conduction through a person\\'s heart. The readings can be used to diagnose cardiac arrhythmias.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['An', 'electrocardiogram', 'is', 'used', 'to', 'record', 'the', 'electrical', 'conduction', 'through', 'a', 'person', \"'s\", 'heart', '.', 'The', 'readings', 'can', 'be', 'used', 'to', 'diagnose', 'cardiac', 'arrhythmias', '.']\n"
     ]
    }
   ],
   "source": [
    "tokenized_by_word = word_tokenize(ecg_text)\n",
    "print(tokenized_by_word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
